{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48271088561613960642858365853327381832862269440000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def product(list1):\n",
    "    total = 1\n",
    "    for n in list1:\n",
    "        total *= n\n",
    "    return total\n",
    "list1 = [i for i in range(1,101) if i % 3 == 0]\n",
    "list2 = [i for i in range(101) if i % 4 == 0]\n",
    "\n",
    "print product(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b580310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "from sklearn import datasets, svm, metrics\n",
    "#Using the premade data sets iris and digits.\n",
    "#Iris contains data for plants I think and\n",
    "#digits contains data from handwritten numbers.\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "#We're using the 'support vector classification' estimator, clf\n",
    "#stands for classify or some such since we're going to try to classify\n",
    "#what digit was written\n",
    "clf = svm.SVC(gamma=0.001,C=100.)\n",
    "\n",
    "clf.fit(digits.data[:-3],digits.target[:-3])\n",
    "clf.predict(digits.data[-3])\n",
    "#print(digits.target[-3])\n",
    "#print(digits.images[-3])\n",
    "pl.imshow(digits.images[-1], cmap=pl.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94  67  88  13  29  28   7  90 100  83 105  58  17  23  69 137  30  76\n",
      " 129 144   5  19  50  33 115 121 101 145  84 139  99  57  47  70  53  49\n",
      "  78 147   3  56 134  74  22  72  64  68  10 148  61 109  92  87  52 114\n",
      "  81  96 117  86   9 108 122  73 142  65  45 107 130 123   1 133 128   2\n",
      " 135  80 102 149  11   4  40  98  24 104 141 116  89 127 103  77  39 106\n",
      " 112  97  55  42 111  15 146  41  60  21 132  46  95 140   0 124  71   8\n",
      " 131  27  43  35 143  26  75  18 126  38  12  79  93  82  59  62  44   6\n",
      "  14  25  37  63  32 110  91 125  20  66  36 113  16  34]\n"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "from datetime import datetime\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "#Random numbers are pseudorandom, the obect in the parentheses is a seed to alter where we look at the \n",
    "#psuedo random numbers. By using the datetime object our seed changes everytime we run it(well, almost every time\n",
    "#there are 10k possible numbers), so the numbers are effectively randomized.\n",
    "np.random.seed(int(str(datetime.now())[-4:]))\n",
    "indices = np.random.permutation(len(iris_X))\n",
    "\n",
    "print(indices[:-10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96111111111111114"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 1: Supervised learning, test prediction performance on digits.\n",
    "#The following tests the knn method\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Use 90% as training, 10% as test data\n",
    "digits_x_train = x_digits[:len(x_digits)*9/10]\n",
    "digits_y_train = y_digits[:len(y_digits)*9/10]\n",
    "digits_x_test = x_digits[len(x_digits)*9/10:]\n",
    "digits_y_test = y_digits[len(y_digits)*9/10:]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(digits_x_train,digits_y_train)\n",
    "knn.predict(digits_x_test)\n",
    "knn.fit(digits_x_train,digits_y_train).score(digits_x_test,digits_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3,\n",
       "       1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 2, 5, 7, 3, 5, 8, 4, 5,\n",
       "       0, 8, 9, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4,\n",
       "       1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 3, 2, 7, 3, 3, 4,\n",
       "       6, 6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4,\n",
       "       6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 5, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4,\n",
       "       4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 1, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(digits_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3,\n",
       "       1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 2, 5, 7, 9, 5, 4, 4, 9,\n",
       "       0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4,\n",
       "       1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 3, 3, 7, 3, 3, 4,\n",
       "       6, 6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4,\n",
       "       6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4,\n",
       "       4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Import the digits dataset, assign data to x, target (answers) to y\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Use 90% as training, 10% as test data\n",
    "digits_x_train = x_digits[:len(x_digits)*9/10]\n",
    "digits_y_train = y_digits[:len(y_digits)*9/10]\n",
    "digits_x_test = x_digits[len(x_digits)*9/10:]\n",
    "digits_y_test = y_digits[len(y_digits)*9/10:]\n",
    "\n",
    "logistic.fit(digits_x_train,digits_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93888888888888888"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(digits_x_train,digits_y_train).score(digits_x_test,digits_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 0, 1, 7, 6, 3, 2, 1, 7, 9, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3,\n",
       "       1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 2, 5, 7, 3, 5, 9, 4, 9,\n",
       "       0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "       9, 0, 8, 2, 8, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4,\n",
       "       1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 8, 8, 7, 5, 8, 4,\n",
       "       6, 6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 4, 7, 6, 3, 2, 1, 7, 4,\n",
       "       6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 5, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4,\n",
       "       4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict(digits_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 8, 0, 1, 7, 6, 3, 2, 1, 7, 4, 6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3,\n",
       "       1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 2, 5, 7, 9, 5, 4, 4, 9,\n",
       "       0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "       9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 9, 5, 5, 6, 5, 0, 9, 8, 9, 8, 4,\n",
       "       1, 7, 7, 3, 5, 1, 0, 0, 2, 2, 7, 8, 2, 0, 1, 2, 6, 3, 3, 7, 3, 3, 4,\n",
       "       6, 6, 6, 4, 9, 1, 5, 0, 9, 5, 2, 8, 2, 0, 0, 1, 7, 6, 3, 2, 1, 7, 4,\n",
       "       6, 3, 1, 3, 9, 1, 7, 6, 8, 4, 3, 1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4,\n",
       "       4, 7, 2, 8, 2, 2, 5, 7, 9, 5, 4, 8, 8, 4, 9, 0, 8, 9, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Exercise: SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from datetime import datetime\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "n=9\n",
    "\n",
    "# Making a psuedo-random number based on current time\n",
    "seed = int(str(datetime.now())[-4:])\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Make a random set of indices from the length of the data\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "xall = iris.data[indices[:len(iris.target)],:2]\n",
    "yall = iris.target[indices[:len(iris.target)]]\n",
    "xall = xall[yall != 0]\n",
    "yall = yall[yall != 0]\n",
    "# Note to self: The above doesn't work with lists in general, iris.data is a special\n",
    "# numpy array. It has functionality like \"ignore the indices where y=0\" (e.g. y!=0)\n",
    "n_sample = len(xall)\n",
    "\n",
    "x = xall[:n_sample*9/10]  # we only take the first two features. We could\n",
    "y = yall[:n_sample*9/10]   # avoid this ugly slicing by using a two-dim dataset\n",
    "\n",
    "xtest = xall[n_sample*9/10:]\n",
    "ytest = yall[n_sample*9/10:]\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C)\n",
    "lin_svc = svm.LinearSVC(C=C)\n",
    "\n",
    "lin_svc.fit(x,y)\n",
    "lin_svc.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear score is 0.7\n",
      "RBF score is 0.6\n",
      "Poly score is 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear score is %s\") % lin_svc.fit(x,y).score(xtest,ytest)\n",
    "print(\"RBF score is %s\") % rbf_svc.fit(x,y).score(xtest,ytest)\n",
    "print(\"Poly score is %s\") % poly_svc.fit(x,y).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(xall[:, 0], xall[:, 1], c=yall, zorder=10, cmap=plt.cm.Paired)\n",
    "    \n",
    "    plt.scatter(xtest[:, 0], xtest[:, 1], s=80, facecolors='none', zorder=10)\n",
    "    \n",
    "    plt.axis('tight')\n",
    "    x_min = xall[:, 0].min()\n",
    "    x_max = xall[:, 0].max()\n",
    "    y_min = xall[:, 1].min()\n",
    "    y_max = xall[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, datasets, svm\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "svc =svm.SVC(kernel='linear')\n",
    "C_s = np.logspace(-10,0,10)\n",
    "\n",
    "scores = list()\n",
    "scores_std = list()\n",
    "for C in C_s:\n",
    "    svc.C=C\n",
    "    this_scores= cross_validation.cross_val_score(svc,X,y,n_jobs=-1)\n",
    "    scores.append(np.mean(this_scores))\n",
    "    scores_std.append(np.std(this_scores))\n",
    "plt.figure(1, figsize=(4,3))\n",
    "plt.clf()\n",
    "plt.semilogx(C_s,scores,'b--')\n",
    "plt.semilogx(C_s, np.array(scores)+np.array(scores_std),'b--')\n",
    "plt.semilogx(C_s, np.array(scores)-np.array(scores_std),'b--')\n",
    "\n",
    "locs,lab = plt.yticks()\n",
    "plt.yticks(locs,list(map(lambda x: \"%g\" % x, locs)))\n",
    "\n",
    "plt.ylabel('CV score')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-10   1.29154967e-09   1.66810054e-08   2.15443469e-07\n",
      "   2.78255940e-06   3.59381366e-05   4.64158883e-04   5.99484250e-03\n",
      "   7.74263683e-02   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "C_s = np.logspace(-10,0,10)\n",
    "print(C_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
