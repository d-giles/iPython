{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b580310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "from sklearn import datasets, svm, metrics\n",
    "#Using the premade data sets iris and digits.\n",
    "#Iris contains data for plants I think and\n",
    "#digits contains data from handwritten numbers.\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "#We're using the 'support vector classification' estimator, clf\n",
    "#stands for classify or some such since we're going to try to classify\n",
    "#what digit was written\n",
    "clf = svm.SVC(gamma=0.001,C=100.)\n",
    "\n",
    "clf.fit(digits.data[:-3],digits.target[:-3])\n",
    "clf.predict(digits.data[-3])\n",
    "#print(digits.target[-3])\n",
    "#print(digits.images[-3])\n",
    "pl.imshow(digits.images[-1], cmap=pl.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "from datetime import datetime\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "\n",
    "#Random numbers are pseudorandom, the obect in the parentheses is a seed to alter where we look at the \n",
    "#psuedo random numbers. By using the datetime object our seed changes everytime we run it(well, almost every time\n",
    "#there are 10k possible numbers), so the numbers are effectively randomized.\n",
    "np.random.seed(int(str(datetime.now())[-4:]))\n",
    "indices = np.random.permutation(len(iris_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96111111111111114"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 1: Supervised learning, test prediction performance on digits.\n",
    "#The following tests the knn method\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Use 90% as training, 10% as test data\n",
    "digits_x_train = x_digits[:len(x_digits)*9/10]\n",
    "digits_y_train = y_digits[:len(y_digits)*9/10]\n",
    "digits_x_test = x_digits[len(x_digits)*9/10:]\n",
    "digits_y_test = y_digits[len(y_digits)*9/10:]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(digits_x_train,digits_y_train)\n",
    "knn.predict(digits_x_test)\n",
    "knn.fit(digits_x_train,digits_y_train).score(digits_x_test,digits_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Import the digits dataset, assign data to x, target (answers) to y\n",
    "digits = datasets.load_digits()\n",
    "x_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Use 90% as training, 10% as test data\n",
    "digits_x_train = x_digits[:len(x_digits)*9/10]\n",
    "digits_y_train = y_digits[:len(y_digits)*9/10]\n",
    "digits_x_test = x_digits[len(x_digits)*9/10:]\n",
    "digits_y_test = y_digits[len(y_digits)*9/10:]\n",
    "\n",
    "logistic.fit(digits_x_train,digits_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93888888888888888"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(digits_x_train,digits_y_train).score(digits_x_test,digits_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Exercise: SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from datetime import datetime\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "n=9\n",
    "\n",
    "# Making a psuedo-random number based on current time\n",
    "seed = int(str(datetime.now())[-4:])\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Make a random set of indices from the length of the data\n",
    "indices = np.random.permutation(len(iris.data))\n",
    "xall = iris.data[indices[:len(iris.target)],:2]\n",
    "yall = iris.target[indices[:len(iris.target)]]\n",
    "xall = xall[yall != 0]\n",
    "yall = yall[yall != 0]\n",
    "# Note to self: The above doesn't work with lists in general, iris.data is a special\n",
    "# numpy array. It has functionality like \"ignore the indices where y=0\" (e.g. y!=0)\n",
    "n_sample = len(xall)\n",
    "\n",
    "x = xall[:n_sample*9/10]  # we only take the first two features. We could\n",
    "y = yall[:n_sample*9/10]   # avoid this ugly slicing by using a two-dim dataset\n",
    "\n",
    "xtest = xall[n_sample*9/10:]\n",
    "ytest = yall[n_sample*9/10:]\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C)\n",
    "lin_svc = svm.LinearSVC(C=C)\n",
    "\n",
    "lin_svc.fit(x,y)\n",
    "lin_svc.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear score is 0.7\n",
      "RBF score is 0.6\n",
      "Poly score is 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear score is %s\") % lin_svc.fit(x,y).score(xtest,ytest)\n",
    "print(\"RBF score is %s\") % rbf_svc.fit(x,y).score(xtest,ytest)\n",
    "print(\"Poly score is %s\") % poly_svc.fit(x,y).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(xall[:, 0], xall[:, 1], c=yall, zorder=10, cmap=plt.cm.Paired)\n",
    "    \n",
    "    plt.scatter(xtest[:, 0], xtest[:, 1], s=80, facecolors='none', zorder=10)\n",
    "    \n",
    "    plt.axis('tight')\n",
    "    x_min = xall[:, 0].min()\n",
    "    x_max = xall[:, 0].max()\n",
    "    y_min = xall[:, 1].min()\n",
    "    y_max = xall[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, datasets, svm\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Support Vector Machine *dot* Support Vector Classifier 'Linear'\n",
    "# Other kernels: Polynomial, rbf\n",
    "svc =svm.SVC(kernel='linear')\n",
    "\n",
    "# np.logspace makes a set of evenly spaced (logarithmically) numbers\n",
    "# np.logspace(min,max,n)\n",
    "# min -> 10^min ; max -> 10^max ; n = number of numbers\n",
    "C_s = np.logspace(-10,0,10)\n",
    "\n",
    "# Will populate score list with the machine's score for given C\n",
    "scores = list()\n",
    "# Will populate score_std with std dev for error bars\n",
    "scores_std = list()\n",
    "\n",
    "for C in C_s:\n",
    "    svc.C = C\n",
    "    # Cross validation splits the data into 3 sets by default, then lists the scores\n",
    "    # in an array or list\n",
    "    this_score= cross_validation.cross_val_score(svc,X,y,n_jobs=-1)\n",
    "    scores.append(np.mean(this_score))\n",
    "    scores_std.append(np.std(this_score))\n",
    "    \n",
    "plt.figure(1, figsize=(4,3))\n",
    "plt.clf()\n",
    "plt.semilogx(C_s,scores,'b--')\n",
    "plt.semilogx(C_s, np.array(scores)+np.array(scores_std),'b--')\n",
    "plt.semilogx(C_s, np.array(scores)-np.array(scores_std),'b--')\n",
    "\n",
    "locs,lab = plt.yticks()\n",
    "plt.yticks(locs,list(map(lambda x: \"%g\" % x, locs)))\n",
    "\n",
    "plt.ylabel('CV score')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-search and c-v estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0788046281567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, datasets, svm, linear_model\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data[:150]\n",
    "y = diabetes.target[:150]\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "alphas = np.logspace(-4,-.5,30)\n",
    "clf = GridSearchCV(estimator=lasso,param_grid=dict(alpha=alphas),n_jobs=-1)\n",
    "clf.fit(X,y)\n",
    "clf.best_score_\n",
    "print(clf.best_estimator_.alpha)\n",
    "\n",
    "#clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/203 0% complete\n"
     ]
    }
   ],
   "source": [
    "i1=90\n",
    "list1 = [i for i in range(203)]\n",
    "for i in range(len(list1)):\n",
    "    if 100.*i/len(list1)%10 < 0.02:\n",
    "        print(\"%s/%s %s%s complete\") % (i,len(list1),100*i/len(list1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
